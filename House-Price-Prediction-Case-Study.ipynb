{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement :\n\nA US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them at a higher price. \n\nThe company wants to know:\n\n1. Which variables are significant in predicting the price of a house, and\n\n2. How well those variables describe the price of a house.\n\n\n\n## Business Goal :\n\nBuild a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\nDetermine the optimal value of lambda for ridge and lasso regression.\nThis model will then be used by the management to understand how exactly the prices vary with the variables\nThey can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns.\nThe model will be a good way for the management to understand the pricing dynamics of a new market.","metadata":{}},{"cell_type":"markdown","source":"## House Price Prediction\n\nThe solution is divided into the following sections: \n- Data understanding and exploration\n- Data cleaning\n- Data preparation\n- Model building and evaluation","metadata":{}},{"cell_type":"markdown","source":"### 1. Data Understanding and Exploration\n\nLet's first import the required libraries and have a look at the dataset and understand the size, attribute names etc.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:27.830235Z","iopub.execute_input":"2023-03-16T14:19:27.830680Z","iopub.status.idle":"2023-03-16T14:19:27.839744Z","shell.execute_reply.started":"2023-03-16T14:19:27.830645Z","shell.execute_reply":"2023-03-16T14:19:27.837912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:27.842794Z","iopub.execute_input":"2023-03-16T14:19:27.843726Z","iopub.status.idle":"2023-03-16T14:19:27.855946Z","shell.execute_reply.started":"2023-03-16T14:19:27.843666Z","shell.execute_reply":"2023-03-16T14:19:27.853966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the dataset\nhouse = pd.read_csv(\"/kaggle/input/house-price-prediction-dataset/train.csv\", na_values=\"NAN\")","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:27.858596Z","iopub.execute_input":"2023-03-16T14:19:27.859229Z","iopub.status.idle":"2023-03-16T14:19:27.895188Z","shell.execute_reply.started":"2023-03-16T14:19:27.859166Z","shell.execute_reply":"2023-03-16T14:19:27.893681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's take a look at the first few rows\nhouse.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:27.999397Z","iopub.execute_input":"2023-03-16T14:19:27.999873Z","iopub.status.idle":"2023-03-16T14:19:28.032347Z","shell.execute_reply.started":"2023-03-16T14:19:27.999835Z","shell.execute_reply":"2023-03-16T14:19:28.030529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(house.info())","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:28.035307Z","iopub.execute_input":"2023-03-16T14:19:28.035777Z","iopub.status.idle":"2023-03-16T14:19:28.063501Z","shell.execute_reply.started":"2023-03-16T14:19:28.035737Z","shell.execute_reply":"2023-03-16T14:19:28.062265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary of the dataset : 1460 rows, 81 columns","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:28.065268Z","iopub.execute_input":"2023-03-16T14:19:28.065979Z","iopub.status.idle":"2023-03-16T14:19:28.071339Z","shell.execute_reply.started":"2023-03-16T14:19:28.065908Z","shell.execute_reply":"2023-03-16T14:19:28.069733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(house['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:28.074726Z","iopub.execute_input":"2023-03-16T14:19:28.075447Z","iopub.status.idle":"2023-03-16T14:19:28.496982Z","shell.execute_reply.started":"2023-03-16T14:19:28.075399Z","shell.execute_reply":"2023-03-16T14:19:28.495496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Skewness: %f\" % house['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % house['SalePrice'].kurt())","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:28.498726Z","iopub.execute_input":"2023-03-16T14:19:28.499142Z","iopub.status.idle":"2023-03-16T14:19:28.509505Z","shell.execute_reply.started":"2023-03-16T14:19:28.499105Z","shell.execute_reply":"2023-03-16T14:19:28.507292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = 'GrLivArea'\ndata = pd.concat([house['SalePrice'], house[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:28.511680Z","iopub.execute_input":"2023-03-16T14:19:28.512823Z","iopub.status.idle":"2023-03-16T14:19:28.819503Z","shell.execute_reply.started":"2023-03-16T14:19:28.512759Z","shell.execute_reply":"2023-03-16T14:19:28.817813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = 'TotalBsmtSF'\ndata = pd.concat([house['SalePrice'], house[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:28.821776Z","iopub.execute_input":"2023-03-16T14:19:28.822837Z","iopub.status.idle":"2023-03-16T14:19:29.211373Z","shell.execute_reply.started":"2023-03-16T14:19:28.822765Z","shell.execute_reply":"2023-03-16T14:19:29.209878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#box plot overallqual/saleprice\nvar = 'OverallQual'\ndata = pd.concat([house['SalePrice'], house[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:29.213366Z","iopub.execute_input":"2023-03-16T14:19:29.214012Z","iopub.status.idle":"2023-03-16T14:19:30.041496Z","shell.execute_reply.started":"2023-03-16T14:19:29.213965Z","shell.execute_reply":"2023-03-16T14:19:30.039536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = 'YearBuilt'\ndata = pd.concat([house['SalePrice'], house[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:30.048463Z","iopub.execute_input":"2023-03-16T14:19:30.050018Z","iopub.status.idle":"2023-03-16T14:19:34.440518Z","shell.execute_reply.started":"2023-03-16T14:19:30.049947Z","shell.execute_reply":"2023-03-16T14:19:34.439604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation matrix\ncorrmat = house.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:34.441824Z","iopub.execute_input":"2023-03-16T14:19:34.442383Z","iopub.status.idle":"2023-03-16T14:19:35.688228Z","shell.execute_reply.started":"2023-03-16T14:19:34.442339Z","shell.execute_reply":"2023-03-16T14:19:35.686820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(house[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:35.689818Z","iopub.execute_input":"2023-03-16T14:19:35.690173Z","iopub.status.idle":"2023-03-16T14:19:36.459166Z","shell.execute_reply.started":"2023-03-16T14:19:35.690139Z","shell.execute_reply":"2023-03-16T14:19:36.457572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(house[cols], size = 2.5)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:36.461478Z","iopub.execute_input":"2023-03-16T14:19:36.461985Z","iopub.status.idle":"2023-03-16T14:19:46.415551Z","shell.execute_reply.started":"2023-03-16T14:19:36.461906Z","shell.execute_reply":"2023-03-16T14:19:46.414652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing data\n\nImportant questions when thinking about missing data:\n\nHow prevalent is the missing data?\nIs missing data random or does it have a pattern?\nThe answer to these questions is important for practical reasons because missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis. Moreover, from a substantive perspective, we need to ensure that the missing data process is not biased and hidding an inconvenient truth.","metadata":{}},{"cell_type":"code","source":"#missing data\ntotal = house.isnull().sum().sort_values(ascending=False)\npercent = (house.isnull().sum()/house.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.416774Z","iopub.execute_input":"2023-03-16T14:19:46.417820Z","iopub.status.idle":"2023-03-16T14:19:46.452035Z","shell.execute_reply.started":"2023-03-16T14:19:46.417781Z","shell.execute_reply":"2023-03-16T14:19:46.451020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imputing Null Values\nWith data this large, it is not surprising that there are a lot of missing values in the cells. In order to effectively train our model we build, we must first deal with the missing values. There are missing values for both numerical and categorical data. We will see how to deal with both.\n\nFor numerical imputing, we would typically fill the missing values with a measure like median, mean, or mode. For categorical imputing, I chose to fill the missing values with the most common term that appeared from the entire column. There are other ways to do the imputing though.\n\n### Places Where NaN Means Something\nIf you look at the data description file provided, you will see that for some categories, NaN actually means something. This means that if a value is NaN, the house might not have that certain attribute, which will affect the price of the house. Therefore, it is better to not drop, but fill in the null cell with a value called \"None\" which serves as its own category.","metadata":{}},{"cell_type":"code","source":"#you can find these features on the description data file provided\n\nnull_has_meaning = [\"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"PoolQC\", \"Fence\", \"MiscFeature\"]","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.453162Z","iopub.execute_input":"2023-03-16T14:19:46.454257Z","iopub.status.idle":"2023-03-16T14:19:46.459220Z","shell.execute_reply.started":"2023-03-16T14:19:46.454221Z","shell.execute_reply":"2023-03-16T14:19:46.457971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in null_has_meaning:\n    house[i].fillna(\"None\", inplace=True)\n    house[i].fillna(\"None\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.460509Z","iopub.execute_input":"2023-03-16T14:19:46.460875Z","iopub.status.idle":"2023-03-16T14:19:46.487106Z","shell.execute_reply.started":"2023-03-16T14:19:46.460826Z","shell.execute_reply":"2023-03-16T14:19:46.486121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imputing \"Real\" NaN Values\n\nThese are the real NaN values that we have to deal with accordingly because they were not recorded.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimport numpy as np\n\nimputer = SimpleImputer(strategy='median')","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.491073Z","iopub.execute_input":"2023-03-16T14:19:46.491976Z","iopub.status.idle":"2023-03-16T14:19:46.498098Z","shell.execute_reply.started":"2023-03-16T14:19:46.491906Z","shell.execute_reply":"2023-03-16T14:19:46.497128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing data\ntotal = house.isnull().sum().sort_values(ascending=False)\npercent = (house.isnull().sum()/house.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(6)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.499385Z","iopub.execute_input":"2023-03-16T14:19:46.500033Z","iopub.status.idle":"2023-03-16T14:19:46.536736Z","shell.execute_reply.started":"2023-03-16T14:19:46.499997Z","shell.execute_reply":"2023-03-16T14:19:46.535526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LotFrontage has too many Null values and it is a numerical value so it may be better to just drop it.","metadata":{}},{"cell_type":"code","source":"house.drop(\"LotFrontage\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.540018Z","iopub.execute_input":"2023-03-16T14:19:46.540366Z","iopub.status.idle":"2023-03-16T14:19:46.547429Z","shell.execute_reply.started":"2023-03-16T14:19:46.540327Z","shell.execute_reply":"2023-03-16T14:19:46.546023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing data\ntotal = house.isnull().sum().sort_values(ascending=False)\npercent = (house.isnull().sum()/house.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.549042Z","iopub.execute_input":"2023-03-16T14:19:46.549393Z","iopub.status.idle":"2023-03-16T14:19:46.583007Z","shell.execute_reply.started":"2023-03-16T14:19:46.549361Z","shell.execute_reply":"2023-03-16T14:19:46.581820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GarageYrBlt, MasVnrArea, and MasVnrType all have a fairly decent amount of missing values. MasVnrType is categorical so we can replace the missing values with \"None\", as we did before. We can fill the others with median.","metadata":{}},{"cell_type":"code","source":"house[\"GarageYrBlt\"].fillna(house[\"GarageYrBlt\"].median(), inplace=True)\nhouse[\"MasVnrArea\"].fillna(house[\"MasVnrArea\"].median(), inplace=True)\nhouse[\"MasVnrType\"].fillna(\"None\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.584445Z","iopub.execute_input":"2023-03-16T14:19:46.584772Z","iopub.status.idle":"2023-03-16T14:19:46.594644Z","shell.execute_reply.started":"2023-03-16T14:19:46.584740Z","shell.execute_reply":"2023-03-16T14:19:46.593234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing data\ntotal = house.isnull().sum().sort_values(ascending=False)\npercent = (house.isnull().sum()/house.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.596201Z","iopub.execute_input":"2023-03-16T14:19:46.597102Z","iopub.status.idle":"2023-03-16T14:19:46.629290Z","shell.execute_reply.started":"2023-03-16T14:19:46.597058Z","shell.execute_reply":"2023-03-16T14:19:46.628293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that only one row has a null entry, we will drop the row.","metadata":{}},{"cell_type":"code","source":"house.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.630595Z","iopub.execute_input":"2023-03-16T14:19:46.630950Z","iopub.status.idle":"2023-03-16T14:19:46.643880Z","shell.execute_reply.started":"2023-03-16T14:19:46.630897Z","shell.execute_reply":"2023-03-16T14:19:46.642538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing data\ntotal = house.isnull().sum().sort_values(ascending=False)\npercent = (house.isnull().sum()/house.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.651973Z","iopub.execute_input":"2023-03-16T14:19:46.652355Z","iopub.status.idle":"2023-03-16T14:19:46.685027Z","shell.execute_reply.started":"2023-03-16T14:19:46.652321Z","shell.execute_reply":"2023-03-16T14:19:46.683809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(house.info())","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.686346Z","iopub.execute_input":"2023-03-16T14:19:46.686697Z","iopub.status.idle":"2023-03-16T14:19:46.713541Z","shell.execute_reply.started":"2023-03-16T14:19:46.686664Z","shell.execute_reply":"2023-03-16T14:19:46.712168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we will determine the data type of all features remaining","metadata":{}},{"cell_type":"code","source":"types_train = house.dtypes #type of each feature in data: int, float, object\nnum_train = types_train[(types_train == 'int64') | (types_train == float)] #numerical values are either type int or float\ncat_train = types_train[types_train == object] #categorical values are type object","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.715216Z","iopub.execute_input":"2023-03-16T14:19:46.715670Z","iopub.status.idle":"2023-03-16T14:19:46.722968Z","shell.execute_reply.started":"2023-03-16T14:19:46.715632Z","shell.execute_reply":"2023-03-16T14:19:46.721751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(types_train).reset_index().set_index(0).reset_index()[0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.724242Z","iopub.execute_input":"2023-03-16T14:19:46.724589Z","iopub.status.idle":"2023-03-16T14:19:46.743566Z","shell.execute_reply.started":"2023-03-16T14:19:46.724554Z","shell.execute_reply":"2023-03-16T14:19:46.742619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we should convert num_train to a list to make it easier to work with\nnumerical_values_train = list(num_train.index)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.745041Z","iopub.execute_input":"2023-03-16T14:19:46.745368Z","iopub.status.idle":"2023-03-16T14:19:46.753659Z","shell.execute_reply.started":"2023-03-16T14:19:46.745337Z","shell.execute_reply":"2023-03-16T14:19:46.752614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(numerical_values_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.754728Z","iopub.execute_input":"2023-03-16T14:19:46.755091Z","iopub.status.idle":"2023-03-16T14:19:46.767707Z","shell.execute_reply.started":"2023-03-16T14:19:46.755055Z","shell.execute_reply":"2023-03-16T14:19:46.766714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are all the numerical features in our data.","metadata":{}},{"cell_type":"code","source":"categorical_values_train = list(cat_train.index)\nprint(categorical_values_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.769301Z","iopub.execute_input":"2023-03-16T14:19:46.769663Z","iopub.status.idle":"2023-03-16T14:19:46.779825Z","shell.execute_reply.started":"2023-03-16T14:19:46.769628Z","shell.execute_reply":"2023-03-16T14:19:46.778737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are all the caregorical features in our data.","metadata":{}},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Ok, now that we have dealt with all the missing values, it looks like it's time for some feature engineering, the second part of our data preprocessing. We need to create feature vectors in order to get the data ready to be fed into our model as training data. This requires us to convert the categorical values into representative numbers.","metadata":{}},{"cell_type":"code","source":"sns.distplot(house[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:46.780875Z","iopub.execute_input":"2023-03-16T14:19:46.781315Z","iopub.status.idle":"2023-03-16T14:19:47.211351Z","shell.execute_reply.started":"2023-03-16T14:19:46.781278Z","shell.execute_reply":"2023-03-16T14:19:47.209797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(np.log(house[\"SalePrice\"]))","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.214059Z","iopub.execute_input":"2023-03-16T14:19:47.215229Z","iopub.status.idle":"2023-03-16T14:19:47.621459Z","shell.execute_reply.started":"2023-03-16T14:19:47.215176Z","shell.execute_reply":"2023-03-16T14:19:47.620160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It appears that the target, SalePrice, is very skewed and a transformation like a logarithm would make it more normally distributed. Machine Learning models tend to work much better with normally distributed targets, rather than greatly skewed targets. By transforming the prices, we can boost model performance.","metadata":{}},{"cell_type":"code","source":"house[\"TransformedPrice\"] = np.log(house[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.622939Z","iopub.execute_input":"2023-03-16T14:19:47.623316Z","iopub.status.idle":"2023-03-16T14:19:47.630037Z","shell.execute_reply.started":"2023-03-16T14:19:47.623276Z","shell.execute_reply":"2023-03-16T14:19:47.628408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(categorical_values_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.631727Z","iopub.execute_input":"2023-03-16T14:19:47.632218Z","iopub.status.idle":"2023-03-16T14:19:47.642951Z","shell.execute_reply.started":"2023-03-16T14:19:47.632169Z","shell.execute_reply":"2023-03-16T14:19:47.641996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in categorical_values_train:\n    feature_set = set(house[i])\n    for j in feature_set:\n        feature_list = list(feature_set)\n        house.loc[house[i] == j, i] = feature_list.index(j)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.644750Z","iopub.execute_input":"2023-03-16T14:19:47.645125Z","iopub.status.idle":"2023-03-16T14:19:47.854217Z","shell.execute_reply.started":"2023-03-16T14:19:47.645092Z","shell.execute_reply":"2023-03-16T14:19:47.852822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"house.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.858397Z","iopub.execute_input":"2023-03-16T14:19:47.858848Z","iopub.status.idle":"2023-03-16T14:19:47.888475Z","shell.execute_reply.started":"2023-03-16T14:19:47.858810Z","shell.execute_reply":"2023-03-16T14:19:47.886992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! It seems like we have changed all the categorical strings into a representative number. We are ready to build our models!","metadata":{}},{"cell_type":"markdown","source":"# Model Building\n\nNow that we've preprocessed and explored our data, we have a much better understanding of the type of data that we're dealing with. Now, we can began to build and test different models for regression to predict the Sale Price of each house.","metadata":{}},{"cell_type":"code","source":"X = house.drop([\"Id\", \"SalePrice\", \"TransformedPrice\"], axis=1).values\ny = house[\"TransformedPrice\"].values","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.890289Z","iopub.execute_input":"2023-03-16T14:19:47.890865Z","iopub.status.idle":"2023-03-16T14:19:47.905645Z","shell.execute_reply.started":"2023-03-16T14:19:47.890818Z","shell.execute_reply":"2023-03-16T14:19:47.904300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.7,\n                                                    test_size = 0.3, random_state=100)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.907492Z","iopub.execute_input":"2023-03-16T14:19:47.908138Z","iopub.status.idle":"2023-03-16T14:19:47.921135Z","shell.execute_reply.started":"2023-03-16T14:19:47.908091Z","shell.execute_reply":"2023-03-16T14:19:47.919903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of alphas to tune\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.922865Z","iopub.execute_input":"2023-03-16T14:19:47.923612Z","iopub.status.idle":"2023-03-16T14:19:47.930145Z","shell.execute_reply.started":"2023-03-16T14:19:47.923572Z","shell.execute_reply":"2023-03-16T14:19:47.928983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the relevant libraries\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import linear_model","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.932078Z","iopub.execute_input":"2023-03-16T14:19:47.932581Z","iopub.status.idle":"2023-03-16T14:19:47.942084Z","shell.execute_reply.started":"2023-03-16T14:19:47.932526Z","shell.execute_reply":"2023-03-16T14:19:47.941086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Lasso\nlasso = Lasso()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:47.943636Z","iopub.execute_input":"2023-03-16T14:19:47.944058Z","iopub.status.idle":"2023-03-16T14:19:53.747480Z","shell.execute_reply.started":"2023-03-16T14:19:47.944021Z","shell.execute_reply":"2023-03-16T14:19:53.745776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:53.750270Z","iopub.execute_input":"2023-03-16T14:19:53.751527Z","iopub.status.idle":"2023-03-16T14:19:53.815917Z","shell.execute_reply.started":"2023-03-16T14:19:53.751454Z","shell.execute_reply":"2023-03-16T14:19:53.814162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:53.818727Z","iopub.execute_input":"2023-03-16T14:19:53.820022Z","iopub.status.idle":"2023-03-16T14:19:54.057835Z","shell.execute_reply.started":"2023-03-16T14:19:53.819950Z","shell.execute_reply":"2023-03-16T14:19:54.056801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 50\n\nlasso = Lasso(alpha=alpha)\n        \nlasso.fit(X_train, y_train) ","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:54.059558Z","iopub.execute_input":"2023-03-16T14:19:54.060093Z","iopub.status.idle":"2023-03-16T14:19:54.086336Z","shell.execute_reply.started":"2023-03-16T14:19:54.060054Z","shell.execute_reply":"2023-03-16T14:19:54.084580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso.coef_","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:54.089854Z","iopub.execute_input":"2023-03-16T14:19:54.091261Z","iopub.status.idle":"2023-03-16T14:19:54.106396Z","shell.execute_reply.started":"2023-03-16T14:19:54.091187Z","shell.execute_reply":"2023-03-16T14:19:54.104340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Ridge\nridge = Ridge()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train, y_train) ","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:54.109612Z","iopub.execute_input":"2023-03-16T14:19:54.111318Z","iopub.status.idle":"2023-03-16T14:19:58.742289Z","shell.execute_reply.started":"2023-03-16T14:19:54.111235Z","shell.execute_reply":"2023-03-16T14:19:58.740498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results = cv_results[cv_results['param_alpha']<=200]\ncv_results.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:58.750189Z","iopub.execute_input":"2023-03-16T14:19:58.751981Z","iopub.status.idle":"2023-03-16T14:19:58.821456Z","shell.execute_reply.started":"2023-03-16T14:19:58.751901Z","shell.execute_reply":"2023-03-16T14:19:58.819721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:58.829218Z","iopub.execute_input":"2023-03-16T14:19:58.834434Z","iopub.status.idle":"2023-03-16T14:19:59.091364Z","shell.execute_reply.started":"2023-03-16T14:19:58.834337Z","shell.execute_reply":"2023-03-16T14:19:59.090126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 10\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\nridge.coef_","metadata":{"execution":{"iopub.status.busy":"2023-03-16T14:19:59.092713Z","iopub.execute_input":"2023-03-16T14:19:59.093141Z","iopub.status.idle":"2023-03-16T14:19:59.119623Z","shell.execute_reply.started":"2023-03-16T14:19:59.093106Z","shell.execute_reply":"2023-03-16T14:19:59.118027Z"},"trusted":true},"execution_count":null,"outputs":[]}]}